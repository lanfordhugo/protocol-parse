#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
V8åè®®é…ç½®ä¸æ–‡æ¡£å¯¹æ¯”åˆ†æå·¥å…·
è‡ªåŠ¨å¯¹æ¯”YAMLé…ç½®æ–‡ä»¶å’Œåè®®æ–‡æ¡£ï¼Œæ‰¾å‡ºå­—æ®µå·®å¼‚ã€ç¼ºå¤±å’Œä¸ä¸€è‡´
æ”¯æŒé€šç”¨å‚æ•°è¾“å…¥ï¼Œå¯å¯¹æ¯”ä»»æ„åè®®é…ç½®å’Œæ–‡æ¡£
"""

import yaml
import re
import os
import sys
import argparse
from typing import Dict, List, Set, Tuple, Optional

def load_yaml_config(config_path: str) -> Dict:
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {}

def detect_document_format(content: str) -> str:
    """æ£€æµ‹æ–‡æ¡£æ ¼å¼ç±»å‹"""
    # æ£€æŸ¥æ˜¯å¦ä¸ºäº‘å¿«å……æ ¼å¼ï¼ˆä½¿ç”¨å¸§ç±»å‹ç ï¼‰
    if re.search(r'\|\s*å¸§ç±»å‹ç \s*\|\s*0x[0-9A-Fa-f]+', content):
        return 'yunkuaichong'
    # æ£€æŸ¥æ˜¯å¦æœ‰MDé”šç‚¹æ ¼å¼çš„CMDå®šä¹‰
    elif re.search(r'<a id="cmd-\d+"></a>', content):
        # è¿›ä¸€æ­¥åŒºåˆ†ç››å¼˜å’ŒV8æ ¼å¼
        if re.search(r'### \d+\.\d+.*\(cmd=\d+\)', content, re.IGNORECASE):
            return 'shenghong'
        elif re.search(r'### [^(]+\(cmd=\d+\)', content, re.IGNORECASE):
            return 'v8'
        else:
            return 'anchor_based'
    # ä¼ ç»Ÿç››å¼˜æ ¼å¼ï¼ˆæ— é”šç‚¹ï¼‰
    elif re.search(r'### \d+\.\d+.*\(CMD=\d+\)', content, re.IGNORECASE):
        return 'shenghong_legacy'
    else:
        return 'unknown'

def parse_protocol_doc(doc_path: str) -> Dict[int, Dict]:
    """è§£æåè®®æ–‡æ¡£ï¼Œæå–CMDå®šä¹‰ - æ”¯æŒå¤šç§æ ¼å¼"""
    try:
        with open(doc_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–åè®®æ–‡æ¡£å¤±è´¥: {e}")
        return {}
    
    # æ£€æµ‹æ–‡æ¡£æ ¼å¼
    doc_format = detect_document_format(content)
    print(f"ğŸ” æ£€æµ‹åˆ°æ–‡æ¡£æ ¼å¼: {doc_format}")
    
    # æ ¹æ®æ ¼å¼é€‰æ‹©è§£ææ–¹æ³•
    if doc_format == 'yunkuaichong':
        return parse_yunkuaichong_protocol(content)
    elif doc_format in ['shenghong', 'v8', 'anchor_based']:
        return parse_anchor_based_protocol(content, doc_format)
    elif doc_format == 'shenghong_legacy':
        return parse_shenghong_legacy_protocol(content)
    else:
        print(f"âš ï¸  æœªçŸ¥æ–‡æ¡£æ ¼å¼ï¼Œå°è¯•ä½¿ç”¨ä¼ ç»Ÿè§£ææ–¹æ³•")
        return parse_shenghong_legacy_protocol(content)

def parse_anchor_based_protocol(content: str, doc_format: str) -> Dict[int, Dict]:
    """è§£æåŸºäºMDé”šç‚¹çš„åè®®æ–‡æ¡£ï¼ˆç››å¼˜å’ŒV8ï¼‰"""
    protocol_cmds = {}
    lines = content.split('\n')
    
    # æŸ¥æ‰¾æ‰€æœ‰å¸¦æœ‰ <a id="cmd-æ•°å­—"></a> é”šç‚¹çš„CMDå®šä¹‰
    cmd_anchors = []
    
    for i, line in enumerate(lines):
        # åŒ¹é…é”šç‚¹æ ¼å¼ï¼š<a id="cmd-001"></a> æˆ– <a id="cmd-1"></a>
        anchor_match = re.search(r'<a id="cmd-(\d+)"></a>', line)
        if anchor_match:
            cmd_num_str = anchor_match.group(1)
            cmd_num = int(cmd_num_str.lstrip('0') or '0')  # å¤„ç†å‰å¯¼é›¶
            
            # æŸ¥æ‰¾ç´§æ¥ç€çš„æ ‡é¢˜è¡Œ
            title_line_idx = i + 1
            if title_line_idx < len(lines):
                title_line = lines[title_line_idx]
                
                # æ ¹æ®æ–‡æ¡£æ ¼å¼åŒ¹é…ä¸åŒçš„æ ‡é¢˜æ¨¡å¼
                if doc_format == 'shenghong':
                    # ç››å¼˜æ ¼å¼ï¼š### 3.1.1  (cmd=1)åå°æœåŠ¡å™¨ä¸‹å‘å……ç”µæ¡©æ•´å½¢å·¥ä½œå‚æ•°
                    title_match = re.match(r'^\s*### .*\(cmd=\d+\)', title_line, re.IGNORECASE)
                elif doc_format == 'v8':
                    # V8æ ¼å¼ï¼š### æ³¨å†Œå¸§(cmd=1) [cmd=001]
                    title_match = re.match(r'^\s*### .*\(cmd=\d+\)', title_line, re.IGNORECASE)
                else:
                    # é€šç”¨é”šç‚¹æ ¼å¼
                    title_match = re.match(r'^\s*#{1,4}', title_line)
                
                if title_match:
                    cmd_anchors.append((i, cmd_num, title_line.strip(), title_line_idx))
    
    print(f"ğŸ” é€šè¿‡é”šç‚¹æ‰¾åˆ° {len(cmd_anchors)} ä¸ªCMDå®šä¹‰")
    
    # å¤„ç†æ¯ä¸ªCMDæ®µè½
    for i, (anchor_idx, cmd_num, title, title_idx) in enumerate(cmd_anchors):
        # ç¡®å®šæ®µè½ç»“æŸä½ç½® - æŸ¥æ‰¾ä¸‹ä¸€ä¸ªé”šç‚¹æˆ–ä¸»è¦ç« èŠ‚
        end_line_idx = len(lines)
        
        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªCMDé”šç‚¹
        if i + 1 < len(cmd_anchors):
            next_anchor_idx = cmd_anchors[i + 1][0]
            end_line_idx = next_anchor_idx
        else:
            # å¦‚æœæ˜¯æœ€åä¸€ä¸ªï¼ŒæŸ¥æ‰¾ä¸‹ä¸€ä¸ªä¸»è¦ç« èŠ‚
            for j in range(title_idx + 1, len(lines)):
                line = lines[j].strip()
                # ä¸»è¦ç« èŠ‚æ ‡é¢˜æˆ–æ–°çš„é”šç‚¹
                if (re.match(r'^\s*#{1,2}\s+\d+\.\d+', line) or 
                    re.search(r'<a id="[^"]*"></a>', line)):
                    end_line_idx = j
                    break
        
        # æå–æ®µè½å†…å®¹
        cmd_lines = lines[anchor_idx:end_line_idx]
        cmd_content = '\n'.join(cmd_lines)
        
        # æå–å­—æ®µå®šä¹‰è¡¨æ ¼
        fields = extract_fields_from_table(cmd_content)
        
        protocol_cmds[cmd_num] = {
            'name': extract_cmd_name_from_title(title, doc_format),
            'fields': fields,
            'raw_content': cmd_content[:200] + '...' if len(cmd_content) > 200 else cmd_content
        }
    
    return protocol_cmds

def parse_yunkuaichong_protocol(content: str) -> Dict[int, Dict]:
    """è§£æäº‘å¿«å……åè®®æ–‡æ¡£ï¼ˆåŸºäºå¸§ç±»å‹ç ï¼‰"""
    protocol_cmds = {}
    lines = content.split('\n')
    
    # æŸ¥æ‰¾æ‰€æœ‰å¸§ç±»å‹ç å®šä¹‰
    frame_type_sections = []
    
    for i, line in enumerate(lines):
        # åŒ¹é…è¡¨æ ¼ä¸­çš„å¸§ç±»å‹ç è¡Œï¼š| å¸§ç±»å‹ç       | 0x01                          |
        frame_match = re.search(r'\|\s*å¸§ç±»å‹ç \s*\|\s*0x([0-9A-Fa-f]+)', line)
        if frame_match:
            hex_str = frame_match.group(1)
            cmd_num = int(hex_str, 16)  # åå…­è¿›åˆ¶è½¬åè¿›åˆ¶
            
            # å‘å‰æŸ¥æ‰¾ç« èŠ‚æ ‡é¢˜
            section_title = "æœªçŸ¥åŠŸèƒ½"
            for j in range(max(0, i - 10), i):
                title_line = lines[j].strip()
                if re.match(r'^\s*#{1,3}\s+.+', title_line):
                    # æå–æ ‡é¢˜å†…å®¹
                    title_match = re.search(r'#{1,3}\s+(.+)', title_line)
                    if title_match:
                        section_title = title_match.group(1).strip()
                        break
            
            frame_type_sections.append((i, cmd_num, section_title, hex_str))
    
    print(f"ğŸ” é€šè¿‡å¸§ç±»å‹ç æ‰¾åˆ° {len(frame_type_sections)} ä¸ªCMDå®šä¹‰")
    
    # å¤„ç†æ¯ä¸ªå¸§ç±»å‹ç æ®µè½
    for i, (line_idx, cmd_num, title, hex_str) in enumerate(frame_type_sections):
        # ç¡®å®šæ®µè½ç»“æŸä½ç½®
        end_line_idx = len(lines)
        
        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªå¸§ç±»å‹ç æˆ–ä¸»è¦ç« èŠ‚
        if i + 1 < len(frame_type_sections):
            next_line_idx = frame_type_sections[i + 1][0]
            end_line_idx = next_line_idx - 10  # ç•™ä¸€äº›ç¼“å†²
        else:
            # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªä¸»è¦ç« èŠ‚
            for j in range(line_idx + 1, len(lines)):
                line = lines[j].strip()
                if re.match(r'^\s*#{1,2}\s+.+', line):
                    end_line_idx = j
                    break
        
        # æå–æ®µè½å†…å®¹
        start_idx = max(0, line_idx - 20)  # å‘å‰æ‰©å±•ä»¥åŒ…å«å®Œæ•´è¡¨æ ¼
        cmd_lines = lines[start_idx:end_line_idx]
        cmd_content = '\n'.join(cmd_lines)
        
        # æå–å­—æ®µå®šä¹‰è¡¨æ ¼
        fields = extract_yunkuaichong_fields(cmd_content)
        
        protocol_cmds[cmd_num] = {
            'name': title,
            'fields': fields,
            'raw_content': cmd_content[:200] + '...' if len(cmd_content) > 200 else cmd_content
        }
    
    return protocol_cmds

def parse_shenghong_legacy_protocol(content: str) -> Dict[int, Dict]:
    """è§£æä¼ ç»Ÿç››å¼˜åè®®æ–‡æ¡£ï¼ˆåŸæœ‰è§£æé€»è¾‘ï¼‰"""
    protocol_cmds = {}
    lines = content.split('\n')
    
    # åŸæœ‰çš„è§£æé€»è¾‘ - æŸ¥æ‰¾æ‰€æœ‰CMDæ ‡é¢˜è¡Œ
    cmd_headers = []
    found_cmds = set()  # ç”¨äºå»é‡ï¼Œé¿å…è§£æé‡å¤çš„CMD
    
    for i, line in enumerate(lines):
        # åŒ¹é…å¤šç§CMDå®šä¹‰æ ¼å¼ï¼š
        # 1. ### 3.2.14  (CMD=123)å……ç”µæ¡©å…·ä½“å‘Šè­¦ä¿¡æ¯ä¸ŠæŠ¥
        # 2. 3.1.1  (CMD=1)åå°æœåŠ¡å™¨ä¸‹å‘å……ç”µæ¡©æ•´å½¢å·¥ä½œå‚æ•°
        # 3. #### 3.1.1  (CMD=1)åå°æœåŠ¡å™¨ä¸‹å‘å……ç”µæ¡©æ•´å½¢å·¥ä½œå‚æ•°
        cmd_pattern = r'^\s*(#{0,4})\s*(\d+\.\d+(?:\.\d+)*)\s*\(CMD=(\d+)\)'
        match = re.match(cmd_pattern, line, re.IGNORECASE)
        if match:
            hash_prefix, section_num, cmd_num_str = match.groups()
            cmd_num = int(cmd_num_str)
            
            # ä¼˜å…ˆé€‰æ‹©æœ‰###å‰ç¼€çš„å®šä¹‰ï¼ˆæ­£æ–‡ï¼‰ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡ç›®å½•ä¸­çš„é‡å¤å®šä¹‰
            priority = len(hash_prefix)  # ###çš„æ•°é‡ï¼Œè¶Šå¤šä¼˜å…ˆçº§è¶Šé«˜
            
            if cmd_num not in found_cmds or priority > 0:
                if cmd_num in found_cmds:
                    # å¦‚æœå·²å­˜åœ¨ä½†å½“å‰æœ‰æ›´é«˜ä¼˜å…ˆçº§ï¼Œæ›¿æ¢ä¹‹å‰çš„
                    cmd_headers = [h for h in cmd_headers if h[1] != cmd_num]
                
                found_cmds.add(cmd_num)
                cmd_headers.append((i, cmd_num, line.strip(), priority))
    
    # å¤„ç†æ¯ä¸ªCMDæ®µè½ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆä¼˜å…ˆçº§é«˜çš„åœ¨å‰ï¼‰
    cmd_headers.sort(key=lambda x: (x[1], -x[3]))  # æŒ‰CMDå·æ’åºï¼Œç„¶åæŒ‰ä¼˜å…ˆçº§é™åº
    
    for i, (line_idx, cmd_num, header, priority) in enumerate(cmd_headers):
        # ç¡®å®šæ®µè½ç»“æŸä½ç½® - æŸ¥æ‰¾ä¸‹ä¸€ä¸ªä¸»è¦ç« èŠ‚
        end_line_idx = len(lines)
        
        # å‘åæœç´¢ï¼Œæ‰¾åˆ°ä¸‹ä¸€ä¸ªä¸»è¦ç« èŠ‚æˆ–ä¸‹ä¸€ä¸ªCMDå®šä¹‰
        for j in range(line_idx + 1, len(lines)):
            line = lines[j].strip()
            # ä¸»è¦ç« èŠ‚ï¼ˆå¦‚ 3.3  å……ç”µä¿¡æ¯æ•°æ®ï¼‰
            if re.match(r'^\s*\d+\.\d+\s+\w+', line) and not line.startswith('#'):
                end_line_idx = j
                break
            # ä¸‹ä¸€ä¸ªCMDå®šä¹‰ï¼ˆä»»ä½•æ ¼å¼ï¼‰
            elif re.match(r'^\s*#{0,4}\s*\d+\.\d+(?:\.\d+)*\s*\(CMD=\d+\)', line, re.IGNORECASE):
                end_line_idx = j
                break
        
        # æå–æ®µè½å†…å®¹
        cmd_lines = lines[line_idx:end_line_idx]
        cmd_content = '\n'.join(cmd_lines)
        
        # æå–å­—æ®µå®šä¹‰è¡¨æ ¼
        fields = extract_fields_from_table(cmd_content)
        
        protocol_cmds[cmd_num] = {
            'name': extract_cmd_name(cmd_content),
            'fields': fields,
            'raw_content': cmd_content[:200] + '...' if len(cmd_content) > 200 else cmd_content
        }
    
    return protocol_cmds

def extract_cmd_name(content: str) -> str:
    """ä»å†…å®¹ä¸­æå–å‘½ä»¤åç§°"""
    lines = content.split('\n')[:10]  # åªçœ‹å‰10è¡Œ
    for line in lines:
        if '###' in line and ('cmd=' in line.lower() or 'CMD=' in line):
            # æå–å‘½ä»¤åç§°
            name_match = re.search(r'###\s*([^(ï¼ˆ]+)', line)
            if name_match:
                return name_match.group(1).strip()
    return "æœªçŸ¥å‘½ä»¤"

def extract_cmd_name_from_title(title: str, doc_format: str) -> str:
    """ä»æ ‡é¢˜è¡Œä¸­æå–å‘½ä»¤åç§°"""
    if doc_format == 'shenghong':
        # ç››å¼˜æ ¼å¼ï¼š### 3.1.1  (cmd=1)åå°æœåŠ¡å™¨ä¸‹å‘å……ç”µæ¡©æ•´å½¢å·¥ä½œå‚æ•°
        match = re.search(r'### \d+\.\d+(?:\.\d+)?\s*\(cmd=\d+\)\s*(.+)', title, re.IGNORECASE)
        if match:
            return match.group(1).strip()
        # å¤‡é€‰æ¨¡å¼ï¼šæå–æ‹¬å·åçš„å†…å®¹
        match = re.search(r'\(cmd=\d+\)\s*(.+)', title, re.IGNORECASE)
        if match:
            return match.group(1).strip()
    elif doc_format == 'v8':
        # V8æ ¼å¼ï¼š### æ³¨å†Œå¸§(cmd=1) [cmd=001]
        match = re.search(r'###\s*([^(]+)\(cmd=\d+\)', title, re.IGNORECASE)
        if match:
            return match.group(1).strip()
    else:
        # é€šç”¨æ ¼å¼ï¼šå°è¯•æå–###åçš„å†…å®¹
        match = re.search(r'#{1,4}\s*(.+)', title)
        if match:
            # å»é™¤æ‹¬å·å†…å®¹
            name = re.sub(r'\([^)]*\)', '', match.group(1)).strip()
            return name if name else "æœªçŸ¥å‘½ä»¤"
    
    return "æœªçŸ¥å‘½ä»¤"

def extract_yunkuaichong_fields(content: str) -> List[Dict]:
    """æå–äº‘å¿«å……åè®®çš„å­—æ®µå®šä¹‰"""
    fields = []
    
    # äº‘å¿«å……ä½¿ç”¨ä¸åŒçš„è¡¨æ ¼æ ¼å¼ï¼ŒæŸ¥æ‰¾å‚æ•°å®šä¹‰è¡¨æ ¼
    # æ ¼å¼ï¼š| åºå· | å‚æ•°åç§° | æ•°æ®ç±»å‹ | é•¿åº¦(Byte) | å¤‡æ³¨ |
    table_pattern = r'\|\s*(\d+)\s*\|\s*([^|]+?)\s*\|\s*([^|]+?)\s*\|\s*([^|]+?)\s*\|\s*([^|]*?)\s*\|'
    matches = re.findall(table_pattern, content)
    
    for match in matches:
        seq_num_str, field_name, data_type, length_str, description = match
        try:
            seq_num = int(seq_num_str)
            
            # å¤„ç†é•¿åº¦å­—æ®µ
            length_str = length_str.strip()
            if length_str.isdigit():
                length = int(length_str)
            else:
                # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
                length_match = re.search(r'(\d+)', length_str)
                if length_match:
                    length = int(length_match.group(1))
                else:
                    length = -1  # æœªçŸ¥é•¿åº¦
            
            fields.append({
                'seq': seq_num,
                'name': field_name.strip(),
                'length': length,
                'data_type': data_type.strip(),
                'description': description.strip()
            })
        except ValueError:
            continue
    
    return fields

def parse_cmd_range(cmd_range_str: str) -> Set[int]:
    """è§£æCMDèŒƒå›´å­—ç¬¦ä¸²ï¼Œè¿”å›CMDå·ç é›†åˆ
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    - å•ä¸ªèŒƒå›´: "1-100"
    - å¤šä¸ªèŒƒå›´: "1-100,200-300"  
    - å…·ä½“CMD: "1,2,104,122"
    - æ··åˆæ ¼å¼: "1-100,104,200-300"
    """
    if not cmd_range_str:
        return set()
    
    cmd_set = set()
    
    # åˆ†å‰²é€—å·åˆ†éš”çš„éƒ¨åˆ†
    parts = [part.strip() for part in cmd_range_str.split(',')]
    
    for part in parts:
        if '-' in part and not part.startswith('-'):
            # èŒƒå›´æ ¼å¼ï¼šstart-end
            try:
                start, end = part.split('-', 1)
                start_num = int(start.strip())
                end_num = int(end.strip())
                
                if start_num <= end_num:
                    cmd_set.update(range(start_num, end_num + 1))
                else:
                    print(f"âš ï¸  è­¦å‘Šï¼šæ— æ•ˆèŒƒå›´ '{part}'ï¼Œèµ·å§‹å€¼å¤§äºç»“æŸå€¼")
            except ValueError:
                print(f"âš ï¸  è­¦å‘Šï¼šæ— æ³•è§£æèŒƒå›´ '{part}'")
        else:
            # å•ä¸ªCMDå·ç 
            try:
                cmd_num = int(part.strip())
                cmd_set.add(cmd_num)
            except ValueError:
                print(f"âš ï¸  è­¦å‘Šï¼šæ— æ³•è§£æCMDå·ç  '{part}'")
    
    return cmd_set

def normalize_repeated_field_name(field_name: str) -> str:
    """å½’ä¸€åŒ–é‡å¤å­—æ®µåç§°ï¼šå°†'å¼€å§‹æ—¶é—´1'ã€'å¼€å§‹æ—¶é—´n'ç­‰å½’ä¸€åŒ–ä¸º'å¼€å§‹æ—¶é—´'"""
    # ç§»é™¤ç»“å°¾çš„æ•°å­—æˆ–å­—æ¯n
    normalized = re.sub(r'[1-9n]$', '', field_name)
    return normalized if normalized != field_name else field_name

def extract_fields_from_table(content: str) -> List[Dict]:
    """ä»åè®®æ–‡æ¡£è¡¨æ ¼ä¸­æå–å­—æ®µå®šä¹‰"""
    fields = []
    
    # æŸ¥æ‰¾è¡¨æ ¼è¡Œï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š
    # 1. å¸¦æ˜Ÿå·çš„åºå·ï¼ˆå¦‚ 4*ã€5*ï¼‰
    # 2. é•¿åº¦å¯ä»¥æ˜¯æ•°å­—æˆ–å­—æ¯ï¼ˆå¦‚ 1ã€2ã€Nï¼‰
    # 3. æ”¯æŒä¸åŒçš„è¡¨æ ¼åˆ†éš”ç¬¦
    table_pattern = r'\|\s*(\d+\*?)\s*\|\s*([^|]+?)\s*\|\s*([^|]+?)\s*\|\s*([^|]*?)\s*\|'
    matches = re.findall(table_pattern, content)
    
    for match in matches:
        seq_num_str, field_name, length_str, description = match
        try:
            # æå–æ•°å­—éƒ¨åˆ†ï¼Œå¿½ç•¥æ˜Ÿå·
            seq_num = int(seq_num_str.rstrip('*'))
            
            # å¤„ç†é•¿åº¦å­—æ®µï¼Œæ”¯æŒæ•°å­—å’Œå­—æ¯
            length_str = length_str.strip()
            if length_str.isdigit():
                length = int(length_str)
            elif length_str.upper() == 'N':
                # Nè¡¨ç¤ºå¯å˜é•¿åº¦ï¼Œè®¾ä¸ºç‰¹æ®Šå€¼
                length = -1
            else:
                # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
                length_match = re.search(r'\d+', length_str)
                if length_match:
                    length = int(length_match.group())
                else:
                    # æ— æ³•è§£æé•¿åº¦ï¼Œè·³è¿‡
                    continue
            
            # å½’ä¸€åŒ–å­—æ®µåï¼ˆå¤„ç†é‡å¤ç»“æ„ï¼‰
            normalized_name = normalize_repeated_field_name(field_name.strip())
            
            fields.append({
                'seq': seq_num,
                'name': normalized_name,
                'length': length,
                'description': description.strip()
            })
        except ValueError:
            continue
    
    # å»é‡ï¼šå¦‚æœæœ‰å¤šä¸ªç›¸åŒçš„å½’ä¸€åŒ–å­—æ®µåï¼Œåªä¿ç•™ç¬¬ä¸€ä¸ªï¼ˆé‡å¤ç»“æ„çš„æ¨¡æ¿ï¼‰
    seen_names = set()
    unique_fields = []
    for field in fields:
        if field['name'] not in seen_names:
            seen_names.add(field['name'])
            unique_fields.append(field)
    
    return unique_fields

def compare_cmd_config(cmd_num: int, yaml_config: Dict, protocol_def: Dict) -> Dict:
    """å¯¹æ¯”å•ä¸ªCMDçš„é…ç½®ä¸åè®®å®šä¹‰"""
    result = {
        'cmd': cmd_num,
        'status': 'OK',
        'issues': [],
        'yaml_fields': [],
        'protocol_fields': protocol_def.get('fields', []),
        'missing_fields': [],
        'extra_fields': [],
        'length_mismatches': []
    }
    
    if cmd_num not in yaml_config.get('cmds', {}):
        result['status'] = 'MISSING'
        result['issues'].append(f"CMD {cmd_num} åœ¨é…ç½®ä¸­å®Œå…¨ç¼ºå¤±")
        return result
    
    yaml_cmd = yaml_config['cmds'][cmd_num]
    
    # è§£æYAMLå­—æ®µ - å¢å¼ºç‰ˆï¼Œæ”¯æŒrepeat_byå’Œå˜é•¿å­—æ®µ
    yaml_fields = []
    if isinstance(yaml_cmd, list):
        for field in yaml_cmd:
            if isinstance(field, dict):
                if 'name' in field:
                    # å¤„ç†æ™®é€šå­—æ®µ
                    yaml_fields.append({
                        'name': field.get('name', ''),
                        'length': field.get('len', 0),
                        'type': field.get('type', ''),
                        'scale': field.get('scale'),
                        'enum': field.get('enum'),
                        'notes': field.get('notes')
                    })
                elif 'repeat_by' in field and 'fields' in field:
                    # å¤„ç†repeat_byç»“æ„ä¸­çš„å­—æ®µ
                    for repeat_field in field['fields']:
                        if isinstance(repeat_field, dict) and 'name' in repeat_field:
                            yaml_fields.append({
                                'name': repeat_field.get('name', ''),
                                'length': repeat_field.get('len', 0),
                                'type': repeat_field.get('type', ''),
                                'scale': repeat_field.get('scale'),
                                'enum': repeat_field.get('enum'),
                                'notes': repeat_field.get('notes', '') + ' [é‡å¤ç»“æ„]'
                            })
    
    result['yaml_fields'] = yaml_fields
    
    # å¯¹æ¯”å­—æ®µ
    protocol_field_names = {f['name'] for f in protocol_def.get('fields', [])}
    yaml_field_names = {f['name'] for f in yaml_fields}
    
    # æŸ¥æ‰¾ç¼ºå¤±å­—æ®µ - æŒ‰åè®®å®šä¹‰é¡ºåºæ’åº
    missing = protocol_field_names - yaml_field_names
    if missing:
        # æŒ‰åè®®å®šä¹‰çš„åºå·é¡ºåºæ’åº
        protocol_fields_ordered = sorted(protocol_def.get('fields', []), key=lambda x: x.get('seq', 999))
        missing_ordered = []
        for field in protocol_fields_ordered:
            if field['name'] in missing:
                missing_ordered.append(field['name'])
        
        result['missing_fields'] = missing_ordered
        # æ„å»ºç¼ºå¤±å­—æ®µçš„æ¸…æ™°æ˜¾ç¤º
        missing_display = '\n      '.join(['- ' + field for field in missing_ordered])
        result['issues'].append(f"ç¼ºå¤±å­—æ®µ:\n      {missing_display}")
    
    # æŸ¥æ‰¾å¤šä½™å­—æ®µ - æŒ‰YAMLé…ç½®é¡ºåºæ’åºï¼ˆä¿æŒé…ç½®æ–‡ä»¶çš„é¡ºåºï¼‰
    extra = yaml_field_names - protocol_field_names
    if extra:
        # æŒ‰YAMLé…ç½®ä¸­çš„é¡ºåºæ’åº
        extra_ordered = []
        for field in yaml_fields:
            if field['name'] in extra:
                extra_ordered.append(field['name'])
        
        result['extra_fields'] = extra_ordered
        # æ„å»ºå¤šä½™å­—æ®µçš„æ¸…æ™°æ˜¾ç¤º
        extra_display = '\n      '.join(['- ' + field for field in extra_ordered])
        result['issues'].append(f"å¤šä½™å­—æ®µ:\n      {extra_display}")
    
    # å¯¹æ¯”å­—æ®µé•¿åº¦ - å¢å¼ºç‰ˆï¼Œæ”¯æŒå˜é•¿å­—æ®µ
    for yaml_field in yaml_fields:
        for protocol_field in protocol_def.get('fields', []):
            if yaml_field['name'] == protocol_field['name']:
                yaml_len = yaml_field['length']
                protocol_len = protocol_field['length']
                
                # å¤„ç†å˜é•¿å­—æ®µï¼šå¦‚æœåè®®é•¿åº¦ä¸º-1ï¼ˆå˜é•¿ï¼‰è€Œé…ç½®ä½¿ç”¨å˜é•¿æ ‡è¯†ç¬¦ï¼Œåˆ™è®¤ä¸ºåŒ¹é…
                is_varlen_match = (protocol_len == -1 and 
                                 isinstance(yaml_len, str) and 
                                 yaml_len not in ['0', '1', '2', '4', '8'])
                
                if yaml_len != protocol_len and not is_varlen_match:
                    result['length_mismatches'].append({
                        'field': yaml_field['name'],
                        'yaml_length': yaml_len,
                        'protocol_length': protocol_len
                    })
                    result['issues'].append(
                        f"å­—æ®µé•¿åº¦ä¸åŒ¹é… '{yaml_field['name']}': "
                        f"é…ç½®={yaml_len}, åè®®={protocol_len}"
                    )
    
    if result['issues']:
        result['status'] = 'MISMATCH'
    
    return result

def analyze_protocol_config(config_path: str, doc_path: str, cmd_range: Optional[str] = None) -> Dict:
    """åˆ†æåè®®é…ç½®ä¸æ–‡æ¡£çš„ä¸€è‡´æ€§"""
    
    print("ğŸ” åè®®é…ç½®ä¸æ–‡æ¡£å¯¹æ¯”åˆ†æ")
    print("=" * 60)
    print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {config_path}")
    print(f"ğŸ“„ åè®®æ–‡æ¡£: {doc_path}")
    if cmd_range:
        print(f"ğŸ¯ CMDèŒƒå›´: {cmd_range}")
    print("=" * 60)
    
    # åŠ è½½é…ç½®æ–‡ä»¶
    print(f"ğŸ“– åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    yaml_config = load_yaml_config(config_path)
    if not yaml_config:
        return {}
    
    # è§£æåè®®æ–‡æ¡£
    print(f"ğŸ“– è§£æåè®®æ–‡æ¡£: {doc_path}")
    protocol_cmds = parse_protocol_doc(doc_path)
    if not protocol_cmds:
        return {}
    
    # è§£æCMDèŒƒå›´è¿‡æ»¤
    allowed_cmds = None
    if cmd_range:
        allowed_cmds = parse_cmd_range(cmd_range)
        if allowed_cmds:
            sorted_cmds = sorted(allowed_cmds)
            if len(sorted_cmds) <= 20:
                print(f"ğŸ¯ è§£æCMDèŒƒå›´: {sorted_cmds} (å…±{len(sorted_cmds)}ä¸ª)")
            else:
                print(f"ğŸ¯ è§£æCMDèŒƒå›´: {sorted_cmds[:10]}...{sorted_cmds[-10:]} (å…±{len(sorted_cmds)}ä¸ª)")
                print(f"   èŒƒå›´æ¦‚è¦: {min(sorted_cmds)}-{max(sorted_cmds)}")
            
            # è¿‡æ»¤åè®®CMD
            original_protocol_count = len(protocol_cmds)
            protocol_cmds = {k: v for k, v in protocol_cmds.items() if k in allowed_cmds}
            
            # è¿‡æ»¤é…ç½®CMDï¼ˆä»…ç”¨äºç»Ÿè®¡ï¼‰
            original_yaml_count = len(yaml_config.get('cmds', {}))
            filtered_yaml_cmds = {k: v for k, v in yaml_config.get('cmds', {}).items() if k in allowed_cmds}
            
            print(f"ğŸ“Š èŒƒå›´è¿‡æ»¤ç»“æœ:")
            print(f"   åè®®æ–‡æ¡£: {original_protocol_count} -> {len(protocol_cmds)} ä¸ªCMD")
            print(f"   é…ç½®æ–‡ä»¶: {original_yaml_count} -> {len(filtered_yaml_cmds)} ä¸ªCMD")
        else:
            print(f"âš ï¸  è­¦å‘Šï¼šCMDèŒƒå›´è§£æå¤±è´¥æˆ–ä¸ºç©ºï¼Œå°†åˆ†ææ‰€æœ‰CMD")
    
    print(f"âœ… åè®®æ–‡æ¡£ä¸­æ‰¾åˆ° {len(protocol_cmds)} ä¸ªCMDå®šä¹‰")
    print(f"âœ… é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ° {len(yaml_config.get('cmds', {}))} ä¸ªCMDé…ç½®")
    print()
    
    # å¯¹æ¯”åˆ†æ
    results = {}
    yaml_cmds = set(yaml_config.get('cmds', {}).keys())
    protocol_cmds_set = set(protocol_cmds.keys())
    
    # åº”ç”¨CMDèŒƒå›´è¿‡æ»¤
    if allowed_cmds:
        yaml_cmds = yaml_cmds & allowed_cmds
        protocol_cmds_set = protocol_cmds_set & allowed_cmds
    
    # ç»Ÿè®¡ä¿¡æ¯
    missing_cmds = protocol_cmds_set - yaml_cmds
    extra_cmds = yaml_cmds - protocol_cmds_set
    common_cmds = yaml_cmds & protocol_cmds_set
    
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   åè®®æ–‡æ¡£CMDæ•°é‡: {len(protocol_cmds_set)}")
    print(f"   é…ç½®æ–‡ä»¶CMDæ•°é‡: {len(yaml_cmds)}")
    print(f"   å…±åŒCMDæ•°é‡: {len(common_cmds)}")
    print(f"   ç¼ºå¤±CMDæ•°é‡: {len(missing_cmds)}")
    print(f"   å¤šä½™CMDæ•°é‡: {len(extra_cmds)}")
    print(f"   è¦†ç›–ç‡: {len(common_cmds)/len(protocol_cmds_set)*100:.1f}%")
    print()
    
    # è¯¦ç»†å¯¹æ¯”æ¯ä¸ªCMD
    mismatch_count = 0
    for cmd_num in sorted(protocol_cmds_set):
        result = compare_cmd_config(cmd_num, yaml_config, protocol_cmds[cmd_num])
        results[cmd_num] = result
        
        if result['status'] == 'MISMATCH':
            mismatch_count += 1
    
    # è¾“å‡ºé—®é¢˜æ±‡æ€»
    print("ğŸš¨ é—®é¢˜æ±‡æ€»:")
    print("-" * 30)
    
    if missing_cmds:
        print(f"âŒ å®Œå…¨ç¼ºå¤±çš„CMD ({len(missing_cmds)}ä¸ª): {sorted(missing_cmds)}")
    
    if extra_cmds:
        print(f"âš ï¸  åè®®ä¸­ä¸å­˜åœ¨çš„CMD ({len(extra_cmds)}ä¸ª): {sorted(extra_cmds)}")
    
    if mismatch_count > 0:
        print(f"âš ï¸  å­—æ®µä¸åŒ¹é…çš„CMD ({mismatch_count}ä¸ª):")
        for cmd_num, result in results.items():
            if result['status'] == 'MISMATCH':
                print(f"   CMD {cmd_num}:")
                for issue in result['issues']:
                    print(f"     {issue}")
                print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”ä¸åŒCMD
    
    if not missing_cmds and not extra_cmds and mismatch_count == 0:
        print("âœ… é…ç½®ä¸åè®®æ–‡æ¡£å®Œå…¨ä¸€è‡´ï¼")
    
    return results

def create_argument_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description='åè®®é…ç½®ä¸æ–‡æ¡£å¯¹æ¯”åˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¯¹æ¯”V8åè®®é…ç½®ä¸æ–‡æ¡£
  python cmd_analysis.py -c configs/v8/protocol.yaml -d protocoltxt/å……ç”µæ¡©ç³»ç»ŸMCU-CCU-M2ä»¥å¤ªç½‘é€šä¿¡åè®®11-10.txt
  
  # åªåˆ†æCMD 1-100èŒƒå›´
  python cmd_analysis.py -c configs/v8/protocol.yaml -d protocoltxt/v8_protocol.txt --cmd-range 1-100
  
  # åˆ†æå¤šä¸ªèŒƒå›´ï¼ˆ3000ä»¥å†…å’Œ3000-4000ï¼‰
  python cmd_analysis.py -c configs/yunwei/protocol.yaml -d protocoltxt/yunwei_protocol.txt --cmd-range 1-3000,3000-4000
  
  # åˆ†æç‰¹å®šCMDåˆ—è¡¨
  python cmd_analysis.py -c configs/v8/protocol.yaml -d protocoltxt/v8_protocol.txt --cmd-range 1,2,104,122
  
  # æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
  python cmd_analysis.py -c configs/v8/protocol.yaml -d protocoltxt/v8_protocol.txt -v
  
  # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
  python cmd_analysis.py -h
        """
    )
    
    parser.add_argument(
        '-c', '--config',
        type=str,
        required=True,
        help='YAMLåè®®é…ç½®æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-d', '--doc',
        type=str,
        required=True,
        help='åè®®æ–‡æ¡£æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡ºä¿¡æ¯'
    )
    
    parser.add_argument(
        '--cmd-range',
        type=str,
        help='æŒ‡å®šè¦åˆ†æçš„CMDèŒƒå›´ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š\n'
             '  å•ä¸ªèŒƒå›´: 1-100\n'
             '  å¤šä¸ªèŒƒå›´: 1-100,200-300\n'
             '  å…·ä½“CMD: 1,2,104,122\n'
             '  æ··åˆæ ¼å¼: 1-100,104,200-300'
    )
    
    parser.add_argument(
        '--version',
        action='version',
        version='åè®®å¯¹æ¯”åˆ†æå·¥å…· v1.0'
    )
    
    return parser

def validate_files(config_path: str, doc_path: str) -> bool:
    """éªŒè¯è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å’Œæœ‰æ•ˆ"""
    errors = []
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(config_path):
        errors.append(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    elif not config_path.lower().endswith(('.yaml', '.yml')):
        errors.append(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸æ˜¯YAMLæ ¼å¼: {config_path}")
    
    # æ£€æŸ¥åè®®æ–‡æ¡£
    if not os.path.exists(doc_path):
        errors.append(f"âŒ åè®®æ–‡æ¡£ä¸å­˜åœ¨: {doc_path}")
    elif not doc_path.lower().endswith(('.txt', '.md', '.doc', '.docx')):
        errors.append(f"âš ï¸  åè®®æ–‡æ¡£æ ¼å¼å¯èƒ½ä¸æ”¯æŒ: {doc_path}")
    
    # è¾“å‡ºé”™è¯¯ä¿¡æ¯
    if errors:
        print("æ–‡ä»¶éªŒè¯å¤±è´¥:")
        for error in errors:
            print(f"  {error}")
        return False
    
    return True

if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = create_argument_parser()
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not validate_files(args.config, args.doc):
        sys.exit(1)
    
    try:
        # æ‰§è¡Œåˆ†æ
        results = analyze_protocol_config(args.config, args.doc, args.cmd_range)
        
        if args.verbose:
            print(f"\nğŸ”§ è¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜åˆ°å†…å­˜ï¼Œå¯è¿›ä¸€æ­¥å¤„ç†")
            
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)
