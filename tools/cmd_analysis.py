#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åè®®é…ç½®ä¸æ–‡æ¡£å¯¹æ¯”åˆ†æå·¥å…· v2.0
=================================

åŠŸèƒ½æè¿°:
    è‡ªåŠ¨å¯¹æ¯”YAMLé…ç½®æ–‡ä»¶å’Œåè®®æ–‡æ¡£ï¼Œæ‰¾å‡ºå­—æ®µå·®å¼‚ã€ç¼ºå¤±å’Œä¸ä¸€è‡´
    æ”¯æŒå¤šç§åè®®æ ¼å¼ï¼šV8ã€ç››å¼˜ã€äº‘å¿«å……ç­‰
    æ™ºèƒ½å¤„ç†Windowsä¸­æ–‡æ–‡ä»¶åç¼–ç é—®é¢˜

æ”¯æŒçš„åè®®æ ¼å¼:
    - V8åè®®: åŸºäºMDé”šç‚¹æ ¼å¼ <a id="cmd-xxx"></a>
    - ç››å¼˜åè®®: ä¼ ç»Ÿç« èŠ‚æ ¼å¼ ### x.x.x (CMD=xxx)
    - äº‘å¿«å……åè®®: å¸§ç±»å‹ç æ ¼å¼ | å¸§ç±»å‹ç  | 0xXX |

ç¼–ç é—®é¢˜è§£å†³æ–¹æ¡ˆ:
    æœ¬å·¥å…·å·²å†…ç½®Windowsä¸­æ–‡æ–‡ä»¶åç¼–ç é—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼š
    
    1. æ™ºèƒ½è·¯å¾„è§„èŒƒåŒ–: è‡ªåŠ¨å¤„ç†ç¼–ç è½¬æ¢é—®é¢˜
    2. é€šé…ç¬¦åŒ¹é…æ”¯æŒ: é¿å…ç›´æ¥ä¼ é€’ä¸­æ–‡æ–‡ä»¶å
    3. å¤šé‡å®¹é”™æœºåˆ¶: å¤„ç†å„ç§ç¼–ç å¼‚å¸¸æƒ…å†µ
    
    æ¨èç”¨æ³•ï¼ˆé¿å…ç¼–ç é—®é¢˜ï¼‰:
    âœ… python cmd_analysis.py -c config.yaml -d "protocoltxt/*MCU*.md" --cmd-range 1-100
    âŒ python cmd_analysis.py -c config.yaml -d "protocoltxt/å……ç”µæ¡©ç³»ç»Ÿ.md" --cmd-range 1-100

ä½¿ç”¨ç¤ºä¾‹:
    # åˆ†æV8åè®®CMD 20-37èŒƒå›´
    python cmd_analysis.py -c configs/v8/protocol.yaml -d "protocoltxt/*MCU-CCU-M2*.md" --cmd-range 20-37
    
    # åˆ†æç››å¼˜åè®®ç‰¹å®šCMD
    python cmd_analysis.py -c configs/shenghong/protocol.yaml -d "protocoltxt/*ç››å¼˜*.md" --cmd-range 1,5,10-20
    
    # åˆ†æäº‘å¿«å……åè®®å®Œæ•´èŒƒå›´
    python cmd_analysis.py -c configs/yunkuaichong/protocol.yaml -d "protocoltxt/*äº‘å¿«å……*.md"
    
    # æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
    python cmd_analysis.py -c config.yaml -d "protocoltxt/*.md" --cmd-range 1-100 -v

CMDèŒƒå›´æ ¼å¼è¯´æ˜:
    - å•ä¸ªèŒƒå›´: 1-100
    - å¤šä¸ªèŒƒå›´: 1-100,200-300  
    - å…·ä½“CMD: 1,2,104,122
    - æ··åˆæ ¼å¼: 1-100,104,200-300

æ³¨æ„äº‹é¡¹:
    1. Windowsç¯å¢ƒå»ºè®®ä½¿ç”¨é€šé…ç¬¦åŒ¹é…æ–‡ä»¶åï¼Œé¿å…ä¸­æ–‡ç¼–ç é—®é¢˜
    2. åè®®æ–‡æ¡£éœ€è¦æ˜¯Markdownæ ¼å¼(.md)æˆ–æ–‡æœ¬æ ¼å¼(.txt)
    3. YAMLé…ç½®æ–‡ä»¶å¿…é¡»ç¬¦åˆé¡¹ç›®çš„åè®®é…ç½®è§„èŒƒ
    4. å¤§å‹åè®®å»ºè®®ä½¿ç”¨--cmd-rangeå‚æ•°é™åˆ¶åˆ†æèŒƒå›´ï¼Œæé«˜æ€§èƒ½

æŠ€æœ¯å®ç°:
    - è‡ªåŠ¨æ£€æµ‹åè®®æ–‡æ¡£æ ¼å¼ç±»å‹
    - æ”¯æŒå˜é•¿å­—æ®µå’Œé‡å¤ç»“æ„è§£æ
    - æ™ºèƒ½å­—æ®µåå½’ä¸€åŒ–å¤„ç†
    - å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œç”¨æˆ·å‹å¥½çš„è¾“å‡º

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 2.0
æ›´æ–°: 2024-12 - å¢åŠ ç¼–ç é—®é¢˜è§£å†³æ–¹æ¡ˆå’Œæ™ºèƒ½è·¯å¾„å¤„ç†
"""

import yaml
import re
import os
import sys
import argparse
from typing import Dict, List, Set, Tuple, Optional

# è®¾ç½®è¾“å‡ºç¼–ç å’Œæ–‡ä»¶ç³»ç»Ÿç¼–ç å¤„ç†
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥æ”¯æŒUTF-8
    os.environ['PYTHONIOENCODING'] = 'utf-8'

def normalize_file_path(file_path: str) -> str:
    """è§„èŒƒåŒ–æ–‡ä»¶è·¯å¾„ï¼Œå¤„ç†ç¼–ç é—®é¢˜"""
    if not file_path:
        return file_path
    
    # å¦‚æœè·¯å¾„åŒ…å«é€šé…ç¬¦ï¼Œå°è¯•globåŒ¹é…
    if '*' in file_path or '?' in file_path:
        import glob
        matches = glob.glob(file_path, recursive=True)
        if matches:
            return matches[0]
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(file_path):
        return file_path
    
    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•åœ¨ç›®å½•ä¸­æŸ¥æ‰¾ç›¸ä¼¼æ–‡ä»¶
    dir_path = os.path.dirname(file_path) or '.'
    filename = os.path.basename(file_path)
    
    if os.path.exists(dir_path):
        try:
            for existing_file in os.listdir(dir_path):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯ï¼ˆå¤„ç†ç¼–ç é—®é¢˜ï¼‰
                try:
                    # å°è¯•å¤šç§ç¼–ç åŒ¹é…
                    keywords = ['MCU-CCU-M2', 'protocol', 'åè®®', 'å……ç”µæ¡©', 'é€šä¿¡åè®®']
                    if any(keyword in existing_file for keyword in keywords):
                        return os.path.join(dir_path, existing_file)
                    
                    # å¦‚æœåŸæ–‡ä»¶ååŒ…å«ä¸­æ–‡ï¼Œå°è¯•åŒ¹é…åŒ…å«å…³é”®è¯çš„æ–‡ä»¶
                    if any(ord(c) > 127 for c in filename):  # åŒ…å«éASCIIå­—ç¬¦
                        # ä¼˜å…ˆåŒ¹é…MCU-CCU-M2æ–‡ä»¶ï¼ˆV8åè®®ï¼‰
                        if 'MCU-CCU-M2' in existing_file and existing_file.endswith('.md'):
                            return os.path.join(dir_path, existing_file)
                        # å¦‚æœåŸæ–‡ä»¶ååŒ…å«"å……ç”µæ¡©"å’Œ"MCU"ï¼Œä¹ŸåŒ¹é…MCU-CCU-M2æ–‡ä»¶
                        if ('å……ç”µæ¡©' in filename or 'MCU' in filename) and 'MCU-CCU-M2' in existing_file:
                            return os.path.join(dir_path, existing_file)
                            
                except (UnicodeDecodeError, UnicodeEncodeError):
                    # ç¼–ç é—®é¢˜æ—¶ï¼Œä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…
                    if 'MCU-CCU-M2' in existing_file:
                        return os.path.join(dir_path, existing_file)
                    
        except (OSError, UnicodeDecodeError):
            pass
    
    return file_path

def load_yaml_config(config_path: str) -> Dict:
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return {}

def detect_document_format(content: str) -> str:
    """æ£€æµ‹æ–‡æ¡£æ ¼å¼ç±»å‹"""
    # æ£€æŸ¥æ˜¯å¦ä¸ºäº‘å¿«å……æ ¼å¼ï¼ˆä½¿ç”¨å¸§ç±»å‹ç ï¼‰
    if re.search(r'\|\s*å¸§ç±»å‹ç \s*\|\s*0x[0-9A-Fa-f]+', content):
        return 'yunkuaichong'
    # æ£€æŸ¥æ˜¯å¦æœ‰MDé”šç‚¹æ ¼å¼çš„CMDå®šä¹‰
    elif re.search(r'<a id="cmd-\d+"></a>', content):
        # è¿›ä¸€æ­¥åŒºåˆ†ç››å¼˜å’ŒV8æ ¼å¼
        if re.search(r'### \d+\.\d+.*\(cmd=\d+\)', content, re.IGNORECASE):
            return 'shenghong'
        elif re.search(r'### [^(]+\(cmd=\d+\)', content, re.IGNORECASE):
            return 'v8'
        else:
            return 'anchor_based'
    # ä¼ ç»Ÿç››å¼˜æ ¼å¼ï¼ˆæ— é”šç‚¹ï¼‰
    elif re.search(r'### \d+\.\d+.*\(CMD=\d+\)', content, re.IGNORECASE):
        return 'shenghong_legacy'
    else:
        return 'unknown'

def parse_protocol_doc(doc_path: str) -> Dict[int, Dict]:
    """è§£æåè®®æ–‡æ¡£ï¼Œæå–CMDå®šä¹‰ - æ”¯æŒå¤šç§æ ¼å¼"""
    try:
        with open(doc_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–åè®®æ–‡æ¡£å¤±è´¥: {e}")
        return {}
    
    # æ£€æµ‹æ–‡æ¡£æ ¼å¼
    doc_format = detect_document_format(content)
    print(f"ğŸ” æ£€æµ‹åˆ°æ–‡æ¡£æ ¼å¼: {doc_format}")
    
    # æ ¹æ®æ ¼å¼é€‰æ‹©è§£ææ–¹æ³•
    if doc_format == 'yunkuaichong':
        return parse_yunkuaichong_protocol(content)
    elif doc_format in ['shenghong', 'v8', 'anchor_based']:
        return parse_anchor_based_protocol(content, doc_format)
    elif doc_format == 'shenghong_legacy':
        return parse_shenghong_legacy_protocol(content)
    else:
        print(f"âš ï¸  æœªçŸ¥æ–‡æ¡£æ ¼å¼ï¼Œå°è¯•ä½¿ç”¨ä¼ ç»Ÿè§£ææ–¹æ³•")
        return parse_shenghong_legacy_protocol(content)

def parse_anchor_based_protocol(content: str, doc_format: str) -> Dict[int, Dict]:
    """è§£æåŸºäºMDé”šç‚¹çš„åè®®æ–‡æ¡£ï¼ˆç››å¼˜å’ŒV8ï¼‰"""
    protocol_cmds = {}
    lines = content.split('\n')
    
    # æŸ¥æ‰¾æ‰€æœ‰å¸¦æœ‰ <a id="cmd-æ•°å­—"></a> é”šç‚¹çš„CMDå®šä¹‰
    cmd_anchors = []
    
    for i, line in enumerate(lines):
        # åŒ¹é…é”šç‚¹æ ¼å¼ï¼š<a id="cmd-001"></a> æˆ– <a id="cmd-1"></a>
        anchor_match = re.search(r'<a id="cmd-(\d+)"></a>', line)
        if anchor_match:
            cmd_num_str = anchor_match.group(1)
            cmd_num = int(cmd_num_str.lstrip('0') or '0')  # å¤„ç†å‰å¯¼é›¶
            
            # æŸ¥æ‰¾ç´§æ¥ç€çš„æ ‡é¢˜è¡Œ
            title_line_idx = i + 1
            if title_line_idx < len(lines):
                title_line = lines[title_line_idx]
                
                # æ ¹æ®æ–‡æ¡£æ ¼å¼åŒ¹é…ä¸åŒçš„æ ‡é¢˜æ¨¡å¼
                if doc_format == 'shenghong':
                    # ç››å¼˜æ ¼å¼ï¼š### 3.1.1  (cmd=1)åå°æœåŠ¡å™¨ä¸‹å‘å……ç”µæ¡©æ•´å½¢å·¥ä½œå‚æ•°
                    title_match = re.match(r'^\s*### .*\(cmd=\d+\)', title_line, re.IGNORECASE)
                elif doc_format == 'v8':
                    # V8æ ¼å¼ï¼š### æ³¨å†Œå¸§(cmd=1) [cmd=001]
                    title_match = re.match(r'^\s*### .*\(cmd=\d+\)', title_line, re.IGNORECASE)
                else:
                    # é€šç”¨é”šç‚¹æ ¼å¼
                    title_match = re.match(r'^\s*#{1,4}', title_line)
                
                if title_match:
                    cmd_anchors.append((i, cmd_num, title_line.strip(), title_line_idx))
    
    print(f"ğŸ” é€šè¿‡é”šç‚¹æ‰¾åˆ° {len(cmd_anchors)} ä¸ªCMDå®šä¹‰")
    
    # å¤„ç†æ¯ä¸ªCMDæ®µè½
    for i, (anchor_idx, cmd_num, title, title_idx) in enumerate(cmd_anchors):
        # ç¡®å®šæ®µè½ç»“æŸä½ç½® - æŸ¥æ‰¾ä¸‹ä¸€ä¸ªé”šç‚¹æˆ–ä¸»è¦ç« èŠ‚
        end_line_idx = len(lines)
        
        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªCMDé”šç‚¹
        if i + 1 < len(cmd_anchors):
            next_anchor_idx = cmd_anchors[i + 1][0]
            end_line_idx = next_anchor_idx
            # åœ¨å½“å‰æ ‡é¢˜ä¸ä¸‹ä¸€ä¸ªé”šç‚¹ä¹‹é—´æŸ¥æ‰¾æ–°çš„æ ‡é¢˜ï¼Œæå‰æˆªæ–­
            for j in range(title_idx + 1, next_anchor_idx):
                line = lines[j].strip()
                if (
                    re.match(r'^\s*#{1,2}\s+\d+\.\d+', line)
                    or (re.match(r'^\s*#{2,4}\s+.+', line) and j != title_idx)
                ):
                    end_line_idx = j
                    break
        else:
            # å¦‚æœæ˜¯æœ€åä¸€ä¸ªï¼ŒæŸ¥æ‰¾ä¸‹ä¸€ä¸ªä¸»è¦ç« èŠ‚
            for j in range(title_idx + 1, len(lines)):
                line = lines[j].strip()
                # ä¸»è¦ç« èŠ‚æ ‡é¢˜æˆ–æ–°çš„é”šç‚¹
                if (
                    re.match(r'^\s*#{1,2}\s+\d+\.\d+', line)
                    or re.search(r'<a id="[^"]*"></a>', line)
                    # æ™®é€šçš„markdownæ ‡é¢˜ï¼ˆå¦‚### æ ‡é¢˜ï¼‰ï¼Œé‡åˆ°ä¸‹ä¸€ä¸ªæ ‡é¢˜ä¹Ÿç»“æŸ
                    or (re.match(r'^\s*#{2,4}\s+.+', line) and j != title_idx)
                ):
                    end_line_idx = j
                    break
        
        
        # æå–æ®µè½å†…å®¹
        cmd_lines = lines[anchor_idx:end_line_idx]
        cmd_content = '\n'.join(cmd_lines)
        
        # æå–å­—æ®µå®šä¹‰è¡¨æ ¼
        fields = extract_fields_from_table(cmd_content)
        
        protocol_cmds[cmd_num] = {
            'name': extract_cmd_name_from_title(title, doc_format),
            'fields': fields,
            'raw_content': cmd_content[:200] + '...' if len(cmd_content) > 200 else cmd_content
        }
    
    return protocol_cmds

def parse_yunkuaichong_protocol(content: str) -> Dict[int, Dict]:
    """è§£æäº‘å¿«å……åè®®æ–‡æ¡£ï¼ˆåŸºäºå¸§ç±»å‹ç ï¼‰"""
    protocol_cmds = {}
    lines = content.split('\n')
    
    # æŸ¥æ‰¾æ‰€æœ‰å¸§ç±»å‹ç å®šä¹‰
    frame_type_sections = []
    
    for i, line in enumerate(lines):
        # åŒ¹é…è¡¨æ ¼ä¸­çš„å¸§ç±»å‹ç è¡Œï¼š| å¸§ç±»å‹ç       | 0x01                          |
        frame_match = re.search(r'\|\s*å¸§ç±»å‹ç \s*\|\s*0x([0-9A-Fa-f]+)', line)
        if frame_match:
            hex_str = frame_match.group(1)
            cmd_num = int(hex_str, 16)  # åå…­è¿›åˆ¶è½¬åè¿›åˆ¶
            
            # å‘å‰æŸ¥æ‰¾ç« èŠ‚æ ‡é¢˜
            section_title = "æœªçŸ¥åŠŸèƒ½"
            for j in range(max(0, i - 10), i):
                title_line = lines[j].strip()
                if re.match(r'^\s*#{1,3}\s+.+', title_line):
                    # æå–æ ‡é¢˜å†…å®¹
                    title_match = re.search(r'#{1,3}\s+(.+)', title_line)
                    if title_match:
                        section_title = title_match.group(1).strip()
                        break
            
            frame_type_sections.append((i, cmd_num, section_title, hex_str))
    
    print(f"ğŸ” é€šè¿‡å¸§ç±»å‹ç æ‰¾åˆ° {len(frame_type_sections)} ä¸ªCMDå®šä¹‰")
    
    # å¤„ç†æ¯ä¸ªå¸§ç±»å‹ç æ®µè½
    for i, (line_idx, cmd_num, title, hex_str) in enumerate(frame_type_sections):
        # ç¡®å®šæ®µè½ç»“æŸä½ç½®
        end_line_idx = len(lines)
        
        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªå¸§ç±»å‹ç æˆ–ä¸»è¦ç« èŠ‚
        if i + 1 < len(frame_type_sections):
            next_line_idx = frame_type_sections[i + 1][0]
            end_line_idx = next_line_idx - 10  # ç•™ä¸€äº›ç¼“å†²
        else:
            # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªä¸»è¦ç« èŠ‚
            for j in range(line_idx + 1, len(lines)):
                line = lines[j].strip()
                if re.match(r'^\s*#{1,2}\s+.+', line):
                    end_line_idx = j
                    break
        
        # æå–æ®µè½å†…å®¹
        start_idx = max(0, line_idx - 20)  # å‘å‰æ‰©å±•ä»¥åŒ…å«å®Œæ•´è¡¨æ ¼
        cmd_lines = lines[start_idx:end_line_idx]
        cmd_content = '\n'.join(cmd_lines)
        
        # æå–å­—æ®µå®šä¹‰è¡¨æ ¼
        fields = extract_yunkuaichong_fields(cmd_content)
        
        protocol_cmds[cmd_num] = {
            'name': title,
            'fields': fields,
            'raw_content': cmd_content[:200] + '...' if len(cmd_content) > 200 else cmd_content
        }
    
    return protocol_cmds

def parse_shenghong_legacy_protocol(content: str) -> Dict[int, Dict]:
    """è§£æä¼ ç»Ÿç››å¼˜åè®®æ–‡æ¡£ï¼ˆåŸæœ‰è§£æé€»è¾‘ï¼‰"""
    protocol_cmds = {}
    lines = content.split('\n')
    
    # åŸæœ‰çš„è§£æé€»è¾‘ - æŸ¥æ‰¾æ‰€æœ‰CMDæ ‡é¢˜è¡Œ
    cmd_headers = []
    found_cmds = set()  # ç”¨äºå»é‡ï¼Œé¿å…è§£æé‡å¤çš„CMD
    
    for i, line in enumerate(lines):
        # åŒ¹é…å¤šç§CMDå®šä¹‰æ ¼å¼ï¼š
        # 1. ### 3.2.14  (CMD=123)å……ç”µæ¡©å…·ä½“å‘Šè­¦ä¿¡æ¯ä¸ŠæŠ¥
        # 2. 3.1.1  (CMD=1)åå°æœåŠ¡å™¨ä¸‹å‘å……ç”µæ¡©æ•´å½¢å·¥ä½œå‚æ•°
        # 3. #### 3.1.1  (CMD=1)åå°æœåŠ¡å™¨ä¸‹å‘å……ç”µæ¡©æ•´å½¢å·¥ä½œå‚æ•°
        cmd_pattern = r'^\s*(#{0,4})\s*(\d+\.\d+(?:\.\d+)*)\s*\(CMD=(\d+)\)'
        match = re.match(cmd_pattern, line, re.IGNORECASE)
        if match:
            hash_prefix, section_num, cmd_num_str = match.groups()
            cmd_num = int(cmd_num_str)
            
            # ä¼˜å…ˆé€‰æ‹©æœ‰###å‰ç¼€çš„å®šä¹‰ï¼ˆæ­£æ–‡ï¼‰ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡ç›®å½•ä¸­çš„é‡å¤å®šä¹‰
            priority = len(hash_prefix)  # ###çš„æ•°é‡ï¼Œè¶Šå¤šä¼˜å…ˆçº§è¶Šé«˜
            
            if cmd_num not in found_cmds or priority > 0:
                if cmd_num in found_cmds:
                    # å¦‚æœå·²å­˜åœ¨ä½†å½“å‰æœ‰æ›´é«˜ä¼˜å…ˆçº§ï¼Œæ›¿æ¢ä¹‹å‰çš„
                    cmd_headers = [h for h in cmd_headers if h[1] != cmd_num]
                
                found_cmds.add(cmd_num)
                cmd_headers.append((i, cmd_num, line.strip(), priority))
    
    # å¤„ç†æ¯ä¸ªCMDæ®µè½ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆä¼˜å…ˆçº§é«˜çš„åœ¨å‰ï¼‰
    cmd_headers.sort(key=lambda x: (x[1], -x[3]))  # æŒ‰CMDå·æ’åºï¼Œç„¶åæŒ‰ä¼˜å…ˆçº§é™åº
    
    for i, (line_idx, cmd_num, header, priority) in enumerate(cmd_headers):
        # ç¡®å®šæ®µè½ç»“æŸä½ç½® - æŸ¥æ‰¾ä¸‹ä¸€ä¸ªä¸»è¦ç« èŠ‚
        end_line_idx = len(lines)
        
        # å‘åæœç´¢ï¼Œæ‰¾åˆ°ä¸‹ä¸€ä¸ªä¸»è¦ç« èŠ‚æˆ–ä¸‹ä¸€ä¸ªCMDå®šä¹‰
        for j in range(line_idx + 1, len(lines)):
            line = lines[j].strip()
            # ä¸»è¦ç« èŠ‚ï¼ˆå¦‚ 3.3  å……ç”µä¿¡æ¯æ•°æ®ï¼‰
            if re.match(r'^\s*\d+\.\d+\s+\w+', line) and not line.startswith('#'):
                end_line_idx = j
                break
            # ä¸‹ä¸€ä¸ªCMDå®šä¹‰ï¼ˆä»»ä½•æ ¼å¼ï¼‰
            elif re.match(r'^\s*#{0,4}\s*\d+\.\d+(?:\.\d+)*\s*\(CMD=\d+\)', line, re.IGNORECASE):
                end_line_idx = j
                break
        
        # æå–æ®µè½å†…å®¹
        cmd_lines = lines[line_idx:end_line_idx]
        cmd_content = '\n'.join(cmd_lines)
        
        # æå–å­—æ®µå®šä¹‰è¡¨æ ¼
        fields = extract_fields_from_table(cmd_content)
        
        protocol_cmds[cmd_num] = {
            'name': extract_cmd_name(cmd_content),
            'fields': fields,
            'raw_content': cmd_content[:200] + '...' if len(cmd_content) > 200 else cmd_content
        }
    
    return protocol_cmds

def extract_cmd_name(content: str) -> str:
    """ä»å†…å®¹ä¸­æå–å‘½ä»¤åç§°"""
    lines = content.split('\n')[:10]  # åªçœ‹å‰10è¡Œ
    for line in lines:
        if '###' in line and ('cmd=' in line.lower() or 'CMD=' in line):
            # æå–å‘½ä»¤åç§°
            name_match = re.search(r'###\s*([^(ï¼ˆ]+)', line)
            if name_match:
                return name_match.group(1).strip()
    return "æœªçŸ¥å‘½ä»¤"

def extract_cmd_name_from_title(title: str, doc_format: str) -> str:
    """ä»æ ‡é¢˜è¡Œä¸­æå–å‘½ä»¤åç§°"""
    if doc_format == 'shenghong':
        # ç››å¼˜æ ¼å¼ï¼š### 3.1.1  (cmd=1)åå°æœåŠ¡å™¨ä¸‹å‘å……ç”µæ¡©æ•´å½¢å·¥ä½œå‚æ•°
        match = re.search(r'### \d+\.\d+(?:\.\d+)?\s*\(cmd=\d+\)\s*(.+)', title, re.IGNORECASE)
        if match:
            return match.group(1).strip()
        # å¤‡é€‰æ¨¡å¼ï¼šæå–æ‹¬å·åçš„å†…å®¹
        match = re.search(r'\(cmd=\d+\)\s*(.+)', title, re.IGNORECASE)
        if match:
            return match.group(1).strip()
    elif doc_format == 'v8':
        # V8æ ¼å¼ï¼š### æ³¨å†Œå¸§(cmd=1) [cmd=001]
        match = re.search(r'###\s*([^(]+)\(cmd=\d+\)', title, re.IGNORECASE)
        if match:
            return match.group(1).strip()
    else:
        # é€šç”¨æ ¼å¼ï¼šå°è¯•æå–###åçš„å†…å®¹
        match = re.search(r'#{1,4}\s*(.+)', title)
        if match:
            # å»é™¤æ‹¬å·å†…å®¹
            name = re.sub(r'\([^)]*\)', '', match.group(1)).strip()
            return name if name else "æœªçŸ¥å‘½ä»¤"
    
    return "æœªçŸ¥å‘½ä»¤"

def extract_yunkuaichong_fields(content: str) -> List[Dict]:
    """æå–äº‘å¿«å……åè®®çš„å­—æ®µå®šä¹‰"""
    fields = []
    
    # äº‘å¿«å……ä½¿ç”¨ä¸åŒçš„è¡¨æ ¼æ ¼å¼ï¼ŒæŸ¥æ‰¾å‚æ•°å®šä¹‰è¡¨æ ¼
    # æ ¼å¼ï¼š| åºå· | å‚æ•°åç§° | æ•°æ®ç±»å‹ | é•¿åº¦(Byte) | å¤‡æ³¨ |
    table_pattern = r'\|\s*(\d+)\s*\|\s*([^|]+?)\s*\|\s*([^|]+?)\s*\|\s*([^|]+?)\s*\|\s*([^|]*?)\s*\|'
    matches = re.findall(table_pattern, content)
    
    for match in matches:
        seq_num_str, field_name, data_type, length_str, description = match
        try:
            seq_num = int(seq_num_str)
            
            # å¤„ç†é•¿åº¦å­—æ®µ
            length_str = length_str.strip()
            if length_str.isdigit():
                length = int(length_str)
            else:
                # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
                length_match = re.search(r'(\d+)', length_str)
                if length_match:
                    length = int(length_match.group(1))
                else:
                    length = -1  # æœªçŸ¥é•¿åº¦
            
            fields.append({
                'seq': seq_num,
                'name': field_name.strip(),
                'length': length,
                'data_type': data_type.strip(),
                'description': description.strip()
            })
        except ValueError:
            continue
    
    return fields

def parse_cmd_range(cmd_range_str: str) -> Set[int]:
    """è§£æCMDèŒƒå›´å­—ç¬¦ä¸²ï¼Œè¿”å›CMDå·ç é›†åˆ
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    - å•ä¸ªèŒƒå›´: "1-100"
    - å¤šä¸ªèŒƒå›´: "1-100,200-300"  
    - å…·ä½“CMD: "1,2,104,122"
    - æ··åˆæ ¼å¼: "1-100,104,200-300"
    """
    if not cmd_range_str:
        return set()
    
    cmd_set = set()
    
    # åˆ†å‰²é€—å·åˆ†éš”çš„éƒ¨åˆ†
    parts = [part.strip() for part in cmd_range_str.split(',')]
    
    for part in parts:
        if '-' in part and not part.startswith('-'):
            # èŒƒå›´æ ¼å¼ï¼šstart-end
            try:
                start, end = part.split('-', 1)
                start_num = int(start.strip())
                end_num = int(end.strip())
                
                if start_num <= end_num:
                    cmd_set.update(range(start_num, end_num + 1))
                else:
                    print(f"âš ï¸  è­¦å‘Šï¼šæ— æ•ˆèŒƒå›´ '{part}'ï¼Œèµ·å§‹å€¼å¤§äºç»“æŸå€¼")
            except ValueError:
                print(f"âš ï¸  è­¦å‘Šï¼šæ— æ³•è§£æèŒƒå›´ '{part}'")
        else:
            # å•ä¸ªCMDå·ç 
            try:
                cmd_num = int(part.strip())
                cmd_set.add(cmd_num)
            except ValueError:
                print(f"âš ï¸  è­¦å‘Šï¼šæ— æ³•è§£æCMDå·ç  '{part}'")
    
    return cmd_set

def normalize_repeated_field_name(field_name: str) -> str:
    """å½’ä¸€åŒ–é‡å¤å­—æ®µåç§°ï¼šå°†'å¼€å§‹æ—¶é—´1'ã€'å¼€å§‹æ—¶é—´n'ç­‰å½’ä¸€åŒ–ä¸º'å¼€å§‹æ—¶é—´'
    ä½†ä¿ç•™ç‹¬ç«‹å­—æ®µå¦‚'åœæ­¢å‚æ•°1-8'ç­‰ä¸åº”è¯¥è¢«å½’ä¸€åŒ–çš„å­—æ®µ"""
    
    # å®šä¹‰ä¸åº”è¯¥è¢«å½’ä¸€åŒ–çš„å­—æ®µæ¨¡å¼ï¼ˆç‹¬ç«‹å­—æ®µï¼‰
    INDEPENDENT_FIELD_PATTERNS = [
        r'åœæ­¢å‚æ•°\d+',      # åœæ­¢å‚æ•°1-8
        r'ä¼ æ„Ÿå™¨\d+',        # ä¼ æ„Ÿå™¨1-N
        r'é€šé“\d+',          # é€šé“1-N
        r'æ¨¡å—\d+',          # æ¨¡å—1-N
        r'è·¯\d+',           # 1è·¯ã€2è·¯ç­‰
        r'æª\d+',           # æª1ã€æª2ç­‰
        r'ç›¸\d+',           # Aç›¸ã€Bç›¸ç­‰ï¼ˆè™½ç„¶ä¸æ˜¯æ•°å­—ï¼Œä½†ç›¸å…³ï¼‰
        r'æ¸©åº¦\d+',         # æ¸©åº¦1-N
        r'ç”µå‹\d+',         # ç”µå‹1-N
        r'ç”µæµ\d+',         # ç”µæµ1-N
        r'åŠŸç‡\d+',         # åŠŸç‡1-N
    ]
    
    # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç‹¬ç«‹å­—æ®µæ¨¡å¼
    for pattern in INDEPENDENT_FIELD_PATTERNS:
        if re.match(pattern, field_name):
            # è¿™æ˜¯ç‹¬ç«‹å­—æ®µï¼Œä¸åº”è¯¥å½’ä¸€åŒ–
            return field_name
    
    # å¯¹äºå…¶ä»–å­—æ®µï¼Œè¿›è¡Œå½’ä¸€åŒ–å¤„ç†
    # åªå½’ä¸€åŒ–æ˜ç¡®çš„é‡å¤æ¨¡å¼ï¼šå¦‚"å¼€å§‹æ—¶é—´1"ã€"å¼€å§‹æ—¶é—´n"ç­‰
    # ä½†è¦æ›´ä¿å®ˆï¼Œåªå¤„ç†æ˜ç¡®çš„é‡å¤ç»“æ„æ ‡è®°
    if re.search(r'[1-9n]$', field_name):
        # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸæ­£çš„é‡å¤ç»“æ„ï¼ˆé€šå¸¸åœ¨æè¿°ä¸­ä¼šæœ‰æç¤ºï¼‰
        # å¦‚æœå­—æ®µåæœ¬èº«å°±æ˜¯ç‹¬ç‰¹çš„ï¼Œä¸è¦å½’ä¸€åŒ–
        base_name = re.sub(r'[1-9n]$', '', field_name)
        
        # å¦‚æœå»æ‰æ•°å­—åçš„åŸºç¡€åç§°å¤ªçŸ­ï¼Œå¯èƒ½ä¸æ˜¯é‡å¤ç»“æ„
        if len(base_name) < 2:
            return field_name
            
        # æ›´ä¿å®ˆçš„å½’ä¸€åŒ–ï¼šåªå¯¹æ˜ç¡®çš„æ—¶é—´ã€åœ°å€ç­‰é‡å¤ç»“æ„è¿›è¡Œå½’ä¸€åŒ–
        if any(keyword in base_name for keyword in ['æ—¶é—´', 'åœ°å€', 'å‚æ•°åœ°å€', 'æ•°æ®', 'ç”µè´¹', 'æœåŠ¡è´¹']):
            return base_name
    
    return field_name

def extract_fields_from_table(content: str) -> List[Dict]:
    """ä»åè®®æ–‡æ¡£è¡¨æ ¼ä¸­æå–å­—æ®µå®šä¹‰"""
    fields = []
    
    # æŸ¥æ‰¾è¡¨æ ¼è¡Œï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š
    # 1. å¸¦æ˜Ÿå·çš„åºå·ï¼ˆå¦‚ 4*ã€5*ï¼‰
    # 2. é•¿åº¦å¯ä»¥æ˜¯æ•°å­—æˆ–å­—æ¯ï¼ˆå¦‚ 1ã€2ã€Nï¼‰
    # 3. æ”¯æŒä¸åŒçš„è¡¨æ ¼åˆ†éš”ç¬¦
    table_pattern = r'\|\s*(\d+\*?)\s*\|\s*([^|]+?)\s*\|\s*([^|]+?)\s*\|\s*([^|]*?)\s*\|'
    matches = re.findall(table_pattern, content)
    
    for match in matches:
        seq_num_str, field_name, length_str, description = match
        try:
            # æå–æ•°å­—éƒ¨åˆ†ï¼Œå¿½ç•¥æ˜Ÿå·
            seq_num = int(seq_num_str.rstrip('*'))
            
            # å¤„ç†é•¿åº¦å­—æ®µï¼Œæ”¯æŒæ•°å­—å’Œå­—æ¯
            length_str = length_str.strip()
            if length_str.isdigit():
                length = int(length_str)
            elif length_str.upper() == 'N':
                # Nè¡¨ç¤ºå¯å˜é•¿åº¦ï¼Œè®¾ä¸ºç‰¹æ®Šå€¼
                length = -1
            else:
                # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å­—
                length_match = re.search(r'\d+', length_str)
                if length_match:
                    length = int(length_match.group())
                else:
                    # æ— æ³•è§£æé•¿åº¦ï¼Œè·³è¿‡
                    continue
            
            # å½’ä¸€åŒ–å­—æ®µåï¼ˆå¤„ç†é‡å¤ç»“æ„ï¼‰
            normalized_name = normalize_repeated_field_name(field_name.strip())
            
            fields.append({
                'seq': seq_num,
                'name': normalized_name,
                'length': length,
                'description': description.strip()
            })
        except ValueError:
            continue
    
    # å»é‡ï¼šå¦‚æœæœ‰å¤šä¸ªç›¸åŒçš„å½’ä¸€åŒ–å­—æ®µåï¼Œåªä¿ç•™ç¬¬ä¸€ä¸ªï¼ˆé‡å¤ç»“æ„çš„æ¨¡æ¿ï¼‰
    seen_names = set()
    unique_fields = []
    for field in fields:
        if field['name'] not in seen_names:
            seen_names.add(field['name'])
            unique_fields.append(field)
    
    return unique_fields

def compare_cmd_config(cmd_num: int, yaml_config: Dict, protocol_def: Dict) -> Dict:
    """å¯¹æ¯”å•ä¸ªCMDçš„é…ç½®ä¸åè®®å®šä¹‰"""
    result = {
        'cmd': cmd_num,
        'status': 'OK',
        'issues': [],
        'yaml_fields': [],
        'protocol_fields': protocol_def.get('fields', []),
        'missing_fields': [],
        'extra_fields': [],
        'length_mismatches': []
    }
    
    if cmd_num not in yaml_config.get('cmds', {}):
        result['status'] = 'MISSING'
        result['issues'].append(f"CMD {cmd_num} åœ¨é…ç½®ä¸­å®Œå…¨ç¼ºå¤±")
        return result
    
    yaml_cmd = yaml_config['cmds'][cmd_num]
    
    # è§£æYAMLå­—æ®µ - å¢å¼ºç‰ˆï¼Œæ”¯æŒrepeat_byå’Œå˜é•¿å­—æ®µ
    yaml_fields = []
    if isinstance(yaml_cmd, list):
        for field in yaml_cmd:
            if isinstance(field, dict):
                if 'name' in field:
                    # å¤„ç†æ™®é€šå­—æ®µ
                    yaml_fields.append({
                        'name': field.get('name', ''),
                        'length': field.get('len', 0),
                        'type': field.get('type', ''),
                        'scale': field.get('scale'),
                        'enum': field.get('enum'),
                        'notes': field.get('notes')
                    })
                elif 'repeat_by' in field and 'fields' in field:
                    # å¤„ç†repeat_byç»“æ„ä¸­çš„å­—æ®µ
                    for repeat_field in field['fields']:
                        if isinstance(repeat_field, dict) and 'name' in repeat_field:
                            notes = repeat_field.get('notes', '')
                            if notes:
                                notes = notes + ' '
                            notes += '[é‡å¤ç»“æ„]'
                            yaml_fields.append({
                                'name': repeat_field.get('name', ''),
                                'length': repeat_field.get('len', 0),
                                'type': repeat_field.get('type', ''),
                                'scale': repeat_field.get('scale'),
                                'enum': repeat_field.get('enum'),
                                'notes': notes
                            })
                elif 'repeat_const' in field and 'fields' in field:
                    for repeat_field in field['fields']:
                        if isinstance(repeat_field, dict) and 'name' in repeat_field:
                            notes = repeat_field.get('notes', '')
                            if notes:
                                notes = notes + ' '
                            notes += '[é‡å¤ç»“æ„]'
                            yaml_fields.append({
                                'name': repeat_field.get('name', ''),
                                'length': repeat_field.get('len', 0),
                                'type': repeat_field.get('type', ''),
                                'scale': repeat_field.get('scale'),
                                'enum': repeat_field.get('enum'),
                                'notes': notes
                            })
    
    result['yaml_fields'] = yaml_fields
    
    # å¯¹æ¯”å­—æ®µ
    protocol_field_names = {f['name'] for f in protocol_def.get('fields', [])}
    yaml_field_names = {f['name'] for f in yaml_fields}
    
    # æŸ¥æ‰¾ç¼ºå¤±å­—æ®µ - æŒ‰åè®®å®šä¹‰é¡ºåºæ’åº
    missing = protocol_field_names - yaml_field_names
    if missing:
        # æŒ‰åè®®å®šä¹‰çš„åºå·é¡ºåºæ’åº
        protocol_fields_ordered = sorted(protocol_def.get('fields', []), key=lambda x: x.get('seq', 999))
        missing_ordered = []
        for field in protocol_fields_ordered:
            if field['name'] in missing:
                missing_ordered.append(field['name'])
        
        result['missing_fields'] = missing_ordered
        # æ„å»ºç¼ºå¤±å­—æ®µçš„æ¸…æ™°æ˜¾ç¤º
        missing_display = '\n      '.join(['- ' + field for field in missing_ordered])
        result['issues'].append(f"ç¼ºå¤±å­—æ®µ:\n      {missing_display}")
    
    # æŸ¥æ‰¾å¤šä½™å­—æ®µ - æŒ‰YAMLé…ç½®é¡ºåºæ’åºï¼ˆä¿æŒé…ç½®æ–‡ä»¶çš„é¡ºåºï¼‰
    extra = yaml_field_names - protocol_field_names
    if extra:
        # æŒ‰YAMLé…ç½®ä¸­çš„é¡ºåºæ’åº
        extra_ordered = []
        for field in yaml_fields:
            if field['name'] in extra:
                extra_ordered.append(field['name'])
        
        result['extra_fields'] = extra_ordered
        # æ„å»ºå¤šä½™å­—æ®µçš„æ¸…æ™°æ˜¾ç¤º
        extra_display = '\n      '.join(['- ' + field for field in extra_ordered])
        result['issues'].append(f"å¤šä½™å­—æ®µ:\n      {extra_display}")
    
    # å¯¹æ¯”å­—æ®µé•¿åº¦ - å¢å¼ºç‰ˆï¼Œæ”¯æŒå˜é•¿å­—æ®µ
    for yaml_field in yaml_fields:
        for protocol_field in protocol_def.get('fields', []):
            if yaml_field['name'] == protocol_field['name']:
                yaml_len = yaml_field['length']
                protocol_len = protocol_field['length']
                
                # å¤„ç†å˜é•¿å­—æ®µï¼šå¦‚æœåè®®é•¿åº¦ä¸º-1ï¼ˆå˜é•¿ï¼‰è€Œé…ç½®ä½¿ç”¨å˜é•¿æ ‡è¯†ç¬¦ï¼Œåˆ™è®¤ä¸ºåŒ¹é…
                is_varlen_match = (protocol_len == -1 and 
                                 isinstance(yaml_len, str) and 
                                 yaml_len not in ['0', '1', '2', '4', '8'])
                
                if yaml_len != protocol_len and not is_varlen_match:
                    result['length_mismatches'].append({
                        'field': yaml_field['name'],
                        'yaml_length': yaml_len,
                        'protocol_length': protocol_len
                    })
                    result['issues'].append(
                        f"å­—æ®µé•¿åº¦ä¸åŒ¹é… '{yaml_field['name']}': "
                        f"é…ç½®={yaml_len}, åè®®={protocol_len}"
                    )
    
    if result['issues']:
        result['status'] = 'MISMATCH'

    # æ£€æµ‹æ˜¯å¦å±äºä½åŸŸæ‹†åˆ†ç­‰éœ€äººå·¥æ ¸æŸ¥çš„åœºæ™¯
    manual_review_message = detect_manual_review_case(result)
    if manual_review_message:
        result['status'] = 'MANUAL_REVIEW'
        result['issues'].append(manual_review_message)
    
    return result


def detect_manual_review_case(result: Dict) -> Optional[str]:
    """è¯†åˆ«æ— æ³•ç”±è‡ªåŠ¨æ¯”å¯¹è¦†ç›–çš„ç‰¹æ®Šåœºæ™¯ï¼Œæç¤ºäººå·¥æ ¸æŸ¥ã€‚

    å½“å‰æ”¯æŒçš„è¯†åˆ«åœºæ™¯ï¼š
    - åè®®å­—æ®µä¸ºæ±‡æ€»ä½å›¾ï¼Œä½†é…ç½®é‡Œæ‹†è§£æˆå¤§é‡å•ç‹¬ä½å­—æ®µ
    """

    missing_fields = result.get('missing_fields', []) or []
    extra_fields = result.get('extra_fields', []) or []
    yaml_fields = result.get('yaml_fields', []) or []

    if missing_fields and extra_fields:
        # ç»Ÿè®¡é¢å¤–å­—æ®µä¸­å¯èƒ½ä»£è¡¨å•ä¸ªä½æˆ–æ‹†åˆ†å­—æ®µçš„ç±»å‹
        extra_field_details = [field for field in yaml_fields if field['name'] in extra_fields]
        if extra_field_details:
            bitfield_like = [
                field for field in extra_field_details
                if (
                    isinstance(field.get('type'), str) and 'bitfield' in field['type']
                )
                or (
                    isinstance(field.get('length'), int)
                    and field['length'] == 1
                    and field.get('type') in {'uint8', 'hex', 'binary_str_1byte'}
                )
            ]

            # å¦‚æœå¤§å¤šæ•°å¤šä½™å­—æ®µæ˜¯ä½å­—æ®µï¼Œä¸”ç¼ºå¤±å­—æ®µç–‘ä¼¼æ±‡æ€»å­—æ®µï¼Œåˆ™æç¤ºäººå·¥å¤„ç†
            if bitfield_like and len(bitfield_like) >= max(4, int(len(extra_field_details) * 0.6)):
                if any(re.search(r'(çŠ¶æ€|åé¦ˆ|å‘Šè­¦|ä½|ä½å›¾)', name) for name in missing_fields):
                    base_names = {
                        re.sub(r'[0-9ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+$', '', name).strip()
                        for name in missing_fields
                    }
                    base_names = {name for name in base_names if name}

                    if not base_names:
                        base_summary = 'åè®®å­—æ®µ'
                    else:
                        base_summary = 'ã€'.join(sorted(base_names))

                    return (
                        f"æ£€æµ‹åˆ°{base_summary}ç­‰åè®®å­—æ®µåœ¨é…ç½®ä¸­è¢«æ‹†åˆ†ä¸ºå¤šä¸ªä½/å­å­—æ®µï¼Œ"
                        f"è‡ªåŠ¨æ¯”å¯¹æ— æ³•å‡†ç¡®åŒ¹é…ï¼Œè¯·å‚è€ƒåè®®é™„å½•äººå·¥æ ¸å¯¹å¯¹åº”ä½å®šä¹‰ã€‚"
                    )

    # å¤„ç†åè®®æŒ‰ç¼–å·å±•å¼€è€Œé…ç½®ä½¿ç”¨é‡å¤ç»“æ„çš„åœºæ™¯
    repeat_fields = [
        field for field in yaml_fields
        if isinstance(field.get('notes'), str) and 'é‡å¤ç»“æ„' in field['notes']
    ]

    if repeat_fields and missing_fields:
        numeric_missing = [name for name in missing_fields if re.search(r'\d', name)]
        if numeric_missing:
            sample_missing = 'ã€'.join(numeric_missing[:3])
            repeat_names = sorted({field['name'] for field in repeat_fields})
            sample_repeat = 'ã€'.join(repeat_names[:3]) if repeat_names else 'å¾ªç¯å­—æ®µ'

            return (
                f"æ£€æµ‹åˆ°åè®®æŒ‰ç¼–å·åˆ—å‡ºå­—æ®µï¼ˆå¦‚ {sample_missing}ï¼‰ï¼Œ"
                f"è€Œé…ç½®ä½¿ç”¨å¾ªç¯ç»“æ„å­—æ®µï¼ˆ{sample_repeat} ç­‰ï¼‰ã€‚"
                f"è‡ªåŠ¨æ¯”å¯¹æ— æ³•ç›´æ¥æ˜ å°„ï¼Œè¯·äººå·¥æ ¸å¯¹å¾ªç¯é¡¹å­—æ®µå«ä¹‰ä¸é¡ºåºã€‚"
            )

    return None

def analyze_protocol_config(config_path: str, doc_path: str, cmd_range: Optional[str] = None) -> Dict:
    """åˆ†æåè®®é…ç½®ä¸æ–‡æ¡£çš„ä¸€è‡´æ€§"""
    
    print("ğŸ” åè®®é…ç½®ä¸æ–‡æ¡£å¯¹æ¯”åˆ†æ")
    print("=" * 60)
    print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {config_path}")
    print(f"ğŸ“„ åè®®æ–‡æ¡£: {doc_path}")
    if cmd_range:
        print(f"ğŸ¯ CMDèŒƒå›´: {cmd_range}")
    print("=" * 60)
    
    # åŠ è½½é…ç½®æ–‡ä»¶
    print(f"ğŸ“– åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    yaml_config = load_yaml_config(config_path)
    if not yaml_config:
        return {}
    
    # è§£æåè®®æ–‡æ¡£
    print(f"ğŸ“– è§£æåè®®æ–‡æ¡£: {doc_path}")
    protocol_cmds = parse_protocol_doc(doc_path)
    if not protocol_cmds:
        return {}
    
    # è§£æCMDèŒƒå›´è¿‡æ»¤
    allowed_cmds = None
    if cmd_range:
        allowed_cmds = parse_cmd_range(cmd_range)
        if allowed_cmds:
            sorted_cmds = sorted(allowed_cmds)
            if len(sorted_cmds) <= 20:
                print(f"ğŸ¯ è§£æCMDèŒƒå›´: {sorted_cmds} (å…±{len(sorted_cmds)}ä¸ª)")
            else:
                print(f"ğŸ¯ è§£æCMDèŒƒå›´: {sorted_cmds[:10]}...{sorted_cmds[-10:]} (å…±{len(sorted_cmds)}ä¸ª)")
                print(f"   èŒƒå›´æ¦‚è¦: {min(sorted_cmds)}-{max(sorted_cmds)}")
            
            # è¿‡æ»¤åè®®CMD
            original_protocol_count = len(protocol_cmds)
            protocol_cmds = {k: v for k, v in protocol_cmds.items() if k in allowed_cmds}
            
            # è¿‡æ»¤é…ç½®CMDï¼ˆä»…ç”¨äºç»Ÿè®¡ï¼‰
            original_yaml_count = len(yaml_config.get('cmds', {}))
            filtered_yaml_cmds = {k: v for k, v in yaml_config.get('cmds', {}).items() if k in allowed_cmds}
            
            print(f"ğŸ“Š èŒƒå›´è¿‡æ»¤ç»“æœ:")
            print(f"   åè®®æ–‡æ¡£: {original_protocol_count} -> {len(protocol_cmds)} ä¸ªCMD")
            print(f"   é…ç½®æ–‡ä»¶: {original_yaml_count} -> {len(filtered_yaml_cmds)} ä¸ªCMD")
        else:
            print(f"âš ï¸  è­¦å‘Šï¼šCMDèŒƒå›´è§£æå¤±è´¥æˆ–ä¸ºç©ºï¼Œå°†åˆ†ææ‰€æœ‰CMD")
    
    print(f"âœ… åè®®æ–‡æ¡£ä¸­æ‰¾åˆ° {len(protocol_cmds)} ä¸ªCMDå®šä¹‰")
    print(f"âœ… é…ç½®æ–‡ä»¶ä¸­æ‰¾åˆ° {len(yaml_config.get('cmds', {}))} ä¸ªCMDé…ç½®")
    print()
    
    # å¯¹æ¯”åˆ†æ
    results = {}
    yaml_cmds = set(yaml_config.get('cmds', {}).keys())
    protocol_cmds_set = set(protocol_cmds.keys())
    
    # åº”ç”¨CMDèŒƒå›´è¿‡æ»¤
    if allowed_cmds:
        yaml_cmds = yaml_cmds & allowed_cmds
        protocol_cmds_set = protocol_cmds_set & allowed_cmds
    
    # ç»Ÿè®¡ä¿¡æ¯
    missing_cmds = protocol_cmds_set - yaml_cmds
    extra_cmds = yaml_cmds - protocol_cmds_set
    common_cmds = yaml_cmds & protocol_cmds_set
    
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   åè®®æ–‡æ¡£CMDæ•°é‡: {len(protocol_cmds_set)}")
    print(f"   é…ç½®æ–‡ä»¶CMDæ•°é‡: {len(yaml_cmds)}")
    print(f"   å…±åŒCMDæ•°é‡: {len(common_cmds)}")
    print(f"   ç¼ºå¤±CMDæ•°é‡: {len(missing_cmds)}")
    print(f"   å¤šä½™CMDæ•°é‡: {len(extra_cmds)}")
    print(f"   è¦†ç›–ç‡: {len(common_cmds)/len(protocol_cmds_set)*100:.1f}%")
    print()
    
    # è¯¦ç»†å¯¹æ¯”æ¯ä¸ªCMD
    mismatch_count = 0
    manual_review_cmds = []
    for cmd_num in sorted(protocol_cmds_set):
        result = compare_cmd_config(cmd_num, yaml_config, protocol_cmds[cmd_num])
        results[cmd_num] = result
        
        if result['status'] == 'MISMATCH':
            mismatch_count += 1
        elif result['status'] == 'MANUAL_REVIEW':
            manual_review_cmds.append(cmd_num)
    
    # è¾“å‡ºé—®é¢˜æ±‡æ€»
    print("ğŸš¨ é—®é¢˜æ±‡æ€»:")
    print("-" * 30)
    
    if missing_cmds:
        print(f"âŒ å®Œå…¨ç¼ºå¤±çš„CMD ({len(missing_cmds)}ä¸ª): {sorted(missing_cmds)}")
    
    if extra_cmds:
        print(f"âš ï¸  åè®®ä¸­ä¸å­˜åœ¨çš„CMD ({len(extra_cmds)}ä¸ª): {sorted(extra_cmds)}")
    
    if mismatch_count > 0:
        print(f"âš ï¸  å­—æ®µä¸åŒ¹é…çš„CMD ({mismatch_count}ä¸ª):")
        for cmd_num, result in results.items():
            if result['status'] == 'MISMATCH':
                print(f"   CMD {cmd_num}:")
                for issue in result['issues']:
                    print(f"     {issue}")
                print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”ä¸åŒCMD
    if manual_review_cmds:
        print(f"ğŸ“  éœ€äººå·¥æ ¸æŸ¥çš„CMD ({len(manual_review_cmds)}ä¸ª):")
        for cmd_num in manual_review_cmds:
            result = results[cmd_num]
            print(f"   CMD {cmd_num}:")
            for issue in result['issues']:
                print(f"     {issue}")
            print()
    
    if not missing_cmds and not extra_cmds and mismatch_count == 0:
        print("âœ… é…ç½®ä¸åè®®æ–‡æ¡£å®Œå…¨ä¸€è‡´ï¼")
    
    return results

def create_argument_parser():
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description='åè®®é…ç½®ä¸æ–‡æ¡£å¯¹æ¯”åˆ†æå·¥å…· v2.0 - æ”¯æŒå¤šç§åè®®æ ¼å¼ï¼Œæ™ºèƒ½å¤„ç†ç¼–ç é—®é¢˜',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:

ğŸ”¥ æ¨èç”¨æ³•ï¼ˆé¿å…ä¸­æ–‡ç¼–ç é—®é¢˜ï¼‰:
  # V8åè®®åˆ†æ - ä½¿ç”¨é€šé…ç¬¦åŒ¹é…
  python cmd_analysis.py -c configs/v8/protocol.yaml -d "protocoltxt/*MCU-CCU-M2*.md" --cmd-range 20-37
  
  # ç››å¼˜åè®®åˆ†æ - ä½¿ç”¨é€šé…ç¬¦åŒ¹é…  
  python cmd_analysis.py -c configs/shenghong/protocol.yaml -d "protocoltxt/*ç››å¼˜*.md" --cmd-range 1-100
  
  # äº‘å¿«å……åè®®åˆ†æ - ä½¿ç”¨é€šé…ç¬¦åŒ¹é…
  python cmd_analysis.py -c configs/yunkuaichong/protocol.yaml -d "protocoltxt/*äº‘å¿«å……*.md"

ğŸ“‹ CMDèŒƒå›´æ ¼å¼:
  --cmd-range 1-100           # å•ä¸ªèŒƒå›´
  --cmd-range 1-100,200-300   # å¤šä¸ªèŒƒå›´  
  --cmd-range 1,2,104,122     # å…·ä½“CMDåˆ—è¡¨
  --cmd-range 1-50,104,200-300 # æ··åˆæ ¼å¼

ğŸ› ï¸ é«˜çº§ç”¨æ³•:
  # æ˜¾ç¤ºè¯¦ç»†åˆ†æä¿¡æ¯
  python cmd_analysis.py -c config.yaml -d "protocoltxt/*.md" --cmd-range 1-100 -v
  
  # åˆ†æå¤§å‹åè®®çš„ç‰¹å®šèŒƒå›´ï¼ˆæé«˜æ€§èƒ½ï¼‰
  python cmd_analysis.py -c config.yaml -d "protocoltxt/*.md" --cmd-range 3000-4000

âš ï¸ ç¼–ç é—®é¢˜è¯´æ˜:
  Windowsç¯å¢ƒä¸‹ï¼Œå»ºè®®ä½¿ç”¨é€šé…ç¬¦åŒ¹é…æ–‡ä»¶åï¼ˆå¦‚ "*MCU*.md"ï¼‰è€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨ä¸­æ–‡æ–‡ä»¶åã€‚
  æœ¬å·¥å…·å·²å†…ç½®æ™ºèƒ½è·¯å¾„å¤„ç†ï¼Œä¼šè‡ªåŠ¨åŒ¹é…æ­£ç¡®çš„åè®®æ–‡æ¡£æ–‡ä»¶ã€‚
  
  âœ… æ¨è: -d "protocoltxt/*MCU*.md"
  âŒ é¿å…: -d "protocoltxt/å……ç”µæ¡©ç³»ç»ŸMCU-CCU-M2ä»¥å¤ªç½‘é€šä¿¡åè®®11-10.md"

ğŸ“– æ”¯æŒçš„åè®®æ ¼å¼:
  - V8åè®®: MDé”šç‚¹æ ¼å¼ <a id="cmd-xxx"></a>
  - ç››å¼˜åè®®: ç« èŠ‚æ ¼å¼ ### x.x.x (CMD=xxx)  
  - äº‘å¿«å……åè®®: å¸§ç±»å‹ç æ ¼å¼ | å¸§ç±»å‹ç  | 0xXX |
        """
    )
    
    parser.add_argument(
        '-c', '--config',
        type=str,
        required=True,
        help='YAMLåè®®é…ç½®æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-d', '--doc',
        type=str,
        required=True,
        help='åè®®æ–‡æ¡£æ–‡ä»¶è·¯å¾„'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡ºä¿¡æ¯'
    )
    
    parser.add_argument(
        '--cmd-range',
        type=str,
        help='æŒ‡å®šè¦åˆ†æçš„CMDèŒƒå›´ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š\n'
             '  å•ä¸ªèŒƒå›´: 1-100\n'
             '  å¤šä¸ªèŒƒå›´: 1-100,200-300\n'
             '  å…·ä½“CMD: 1,2,104,122\n'
             '  æ··åˆæ ¼å¼: 1-100,104,200-300'
    )
    
    parser.add_argument(
        '--version',
        action='version',
        version='åè®®å¯¹æ¯”åˆ†æå·¥å…· v2.0 - æ™ºèƒ½ç¼–ç å¤„ç†ç‰ˆæœ¬'
    )
    
    return parser

def validate_files(config_path: str, doc_path: str) -> Tuple[bool, str, str]:
    """éªŒè¯è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å’Œæœ‰æ•ˆï¼Œè¿”å›(æ˜¯å¦æœ‰æ•ˆ, è§„èŒƒåŒ–é…ç½®è·¯å¾„, è§„èŒƒåŒ–æ–‡æ¡£è·¯å¾„)"""
    errors = []
    
    # è§„èŒƒåŒ–è·¯å¾„
    normalized_config = normalize_file_path(config_path)
    normalized_doc = normalize_file_path(doc_path)
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(normalized_config):
        errors.append(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        if normalized_config != config_path:
            errors.append(f"   å°è¯•è§„èŒƒåŒ–ä¸º: {normalized_config}")
    elif not normalized_config.lower().endswith(('.yaml', '.yml')):
        errors.append(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸æ˜¯YAMLæ ¼å¼: {normalized_config}")
    
    # æ£€æŸ¥åè®®æ–‡æ¡£
    if not os.path.exists(normalized_doc):
        errors.append(f"âŒ åè®®æ–‡æ¡£ä¸å­˜åœ¨: {doc_path}")
        if normalized_doc != doc_path:
            errors.append(f"   å°è¯•è§„èŒƒåŒ–ä¸º: {normalized_doc}")
    elif not normalized_doc.lower().endswith(('.txt', '.md', '.doc', '.docx')):
        errors.append(f"âš ï¸  åè®®æ–‡æ¡£æ ¼å¼å¯èƒ½ä¸æ”¯æŒ: {normalized_doc}")
    
    # è¾“å‡ºé”™è¯¯ä¿¡æ¯æˆ–æˆåŠŸä¿¡æ¯
    if errors:
        print("æ–‡ä»¶éªŒè¯å¤±è´¥:")
        for error in errors:
            print(f"  {error}")
        return False, config_path, doc_path
    else:
        # å¦‚æœè·¯å¾„è¢«è§„èŒƒåŒ–äº†ï¼Œæ˜¾ç¤ºä¿¡æ¯
        if normalized_config != config_path:
            print(f"ğŸ“ é…ç½®æ–‡ä»¶è·¯å¾„å·²è§„èŒƒåŒ–: {normalized_config}")
        if normalized_doc != doc_path:
            print(f"ğŸ“ åè®®æ–‡æ¡£è·¯å¾„å·²è§„èŒƒåŒ–: {normalized_doc}")
        return True, normalized_config, normalized_doc

if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = create_argument_parser()
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    is_valid, config_path, doc_path = validate_files(args.config, args.doc)
    if not is_valid:
        sys.exit(1)
    
    try:
        # æ‰§è¡Œåˆ†æ
        results = analyze_protocol_config(config_path, doc_path, args.cmd_range)
        
        if args.verbose:
            print(f"\nğŸ”§ è¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜åˆ°å†…å­˜ï¼Œå¯è¿›ä¸€æ­¥å¤„ç†")
            
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)
